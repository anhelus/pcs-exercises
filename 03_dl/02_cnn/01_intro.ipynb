{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa lezione vedremo come configurare dei (semplici) modelli di CNN.\n",
    "\n",
    "Lavoreremo sul dataset MNIST, che contiene $60.000$ immagini di numeri scritti a mano. Ovviamente, il problema che affronteremo sarà un problema *multiclasse*, in cui il numero di classi è pari a $10$, tante quante sono le cifre in base decimale.\n",
    "\n",
    "Ogni immagine presente nel dataset avrà dimensioni pari a $28 \\times 28$ pixel; inoltre, essendo presente soltanto un canale, l'immagine sarà monocromatica, a livelli di grigio. Iniziamo quindi andando a creare due costanti (`NUM_CLASSES` ed `INPUT_SHAPE`) che caratterizzino rispettivamente il numero di classi e le dimensioni di ciascuna immagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "\n",
    "\n",
    "def preprocess(design_matrix):\n",
    "    X = design_matrix.astype('float32') / 255\n",
    "    if not X.shape[-1] in [1, 3]:\n",
    "        X = np.expand_dims(X, -1)\n",
    "    return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che `INPUT_SHAPE` tiene conto anche del numero di canali presenti nell'immagine.\n",
    "\n",
    "La funzione `preprocess` agisce sulla matrice di design, convertendola in formato `float`, se necessario, e riportandola tra `0` ed `1`. Inoltre, aggiunge una dimensione ad `X`, se necessario, per fare in modo che sia organizzabile secondo un batch.\n",
    "\n",
    "Applichiamo questa funzione ad `X_train` ed `X_test`, ed utilizziamo la funzione `to_categorical` per convertire `y_train` ed `y_test` usando il one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train\n",
    "# Preprocessing X_train - X_test\n",
    "X_train = preprocess(X_train)\n",
    "X_test = preprocess(X_test)\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostriamo a schermo le prime nove immagini del dataset `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(X_train[i, :, :, :], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo un primo semplice modello che abbia un singolo layer convoluzionale seguito da un layer di max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5408)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                54090     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,410\n",
      "Trainable params: 54,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model creation\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=INPUT_SHAPE))\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall()\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.5140 - categorical_accuracy: 0.8607 - precision: 0.9308 - recall: 0.7720\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3166 - categorical_accuracy: 0.9076 - precision: 0.9303 - recall: 0.8864\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2920 - categorical_accuracy: 0.9153 - precision: 0.9350 - recall: 0.8978\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2725 - categorical_accuracy: 0.9213 - precision: 0.9395 - recall: 0.9050\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2503 - categorical_accuracy: 0.9285 - precision: 0.9455 - recall: 0.9138\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2250 - categorical_accuracy: 0.9367 - precision: 0.9526 - recall: 0.9233\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1982 - categorical_accuracy: 0.9447 - precision: 0.9587 - recall: 0.9327\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1732 - categorical_accuracy: 0.9521 - precision: 0.9646 - recall: 0.9419\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1519 - categorical_accuracy: 0.9584 - precision: 0.9696 - recall: 0.9487\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1342 - categorical_accuracy: 0.9639 - precision: 0.9736 - recall: 0.9555\n"
     ]
    }
   ],
   "source": [
    "history_simple = model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo ad aumentare la complessità del modello inserendo due layer convoluzionali consecutivi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                8010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,578\n",
      "Trainable params: 17,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=INPUT_SHAPE))\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\n",
    "        keras.metrics.CategoricalAccuracy(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall()\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.5967 - categorical_accuracy: 0.8223 - precision_1: 0.9299 - recall_1: 0.7315\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1821 - categorical_accuracy: 0.9456 - precision_1: 0.9583 - recall_1: 0.9347\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1319 - categorical_accuracy: 0.9600 - precision_1: 0.9678 - recall_1: 0.9530\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1088 - categorical_accuracy: 0.9673 - precision_1: 0.9736 - recall_1: 0.9622\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0949 - categorical_accuracy: 0.9702 - precision_1: 0.9759 - recall_1: 0.9662\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0851 - categorical_accuracy: 0.9740 - precision_1: 0.9782 - recall_1: 0.9703\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0784 - categorical_accuracy: 0.9754 - precision_1: 0.9792 - recall_1: 0.9721\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0722 - categorical_accuracy: 0.9776 - precision_1: 0.9814 - recall_1: 0.9750\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0678 - categorical_accuracy: 0.9791 - precision_1: 0.9823 - recall_1: 0.9765\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0637 - categorical_accuracy: 0.9804 - precision_1: 0.9836 - recall_1: 0.9776\n"
     ]
    }
   ],
   "source": [
    "history_complex = model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completiamo il modello usando un layer di Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 5, 32)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                8010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,578\n",
      "Trainable params: 17,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=INPUT_SHAPE))\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=[\n",
    "        keras.metrics.CategoricalAccuracy(),\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall()\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.7557 - categorical_accuracy: 0.7571 - precision_2: 0.9055 - recall_2: 0.6495\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2481 - categorical_accuracy: 0.9269 - precision_2: 0.9446 - recall_2: 0.9092\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1890 - categorical_accuracy: 0.9436 - precision_2: 0.9560 - recall_2: 0.9324\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1635 - categorical_accuracy: 0.9512 - precision_2: 0.9606 - recall_2: 0.9425\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1448 - categorical_accuracy: 0.9575 - precision_2: 0.9656 - recall_2: 0.9500\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1350 - categorical_accuracy: 0.9598 - precision_2: 0.9669 - recall_2: 0.9531\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1253 - categorical_accuracy: 0.9627 - precision_2: 0.9689 - recall_2: 0.9575\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1164 - categorical_accuracy: 0.9654 - precision_2: 0.9714 - recall_2: 0.9599\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1146 - categorical_accuracy: 0.9655 - precision_2: 0.9713 - recall_2: 0.9609\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1066 - categorical_accuracy: 0.9678 - precision_2: 0.9727 - recall_2: 0.9631\n"
     ]
    }
   ],
   "source": [
    "history_dropout = model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
